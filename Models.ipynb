{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc421e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363b836",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536cf11",
   "metadata": {},
   "source": [
    "## Load  RGB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9677751",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_1 = pickle.load(open(\"data/data_train_flatten_batch_1.pkl\", \"rb\"))\n",
    "data_train_2 = pickle.load(open(\"data/data_train_flatten_batch_2.pkl\", \"rb\"))\n",
    "labels_train_1 = pickle.load(open(\"data/labels_train_batch_1.pkl\", \"rb\"))\n",
    "labels_train_2 = pickle.load(open(\"data/labels_train_batch_2.pkl\", \"rb\"))\n",
    "\n",
    "data_train = np.concatenate((data_train_1, data_train_2))\n",
    "labels_train = np.concatenate((labels_train_1, labels_train_2))\n",
    "\n",
    "data_test = pickle.load(open(\"data/data_test_flatten.pkl\", \"rb\"))\n",
    "labels_test = pickle.load(open(\"data/labels_test.pkl\", \"rb\"))\n",
    "\n",
    "# Shuffle train set\n",
    "data_train, labels_train = shuffle(data_train, labels_train, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5c1ad",
   "metadata": {},
   "source": [
    "## Load black and white data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807ff9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = []\n",
    "labels_batches = []\n",
    "\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    data_filepath = \"data/data_train_bw_flatten_batch_\" + str(i) + \".pkl\"\n",
    "    labels_filepath = \"data/labels_train_bw_batch_\" + str(i) + \".pkl\"\n",
    "    train_batches.append(pickle.load(open(data_filepath, \"rb\")))\n",
    "    labels_batches.append(pickle.load(open(labels_filepath, \"rb\")))\n",
    "    \n",
    "data_train_bw = np.concatenate(train_batches)\n",
    "labels_train_bw = np.concatenate(labels_batches)\n",
    "\n",
    "data_test_bw = pickle.load(open(\"data/data_test_bw_flatten.pkl\", \"rb\"))\n",
    "labels_test_bw = pickle.load(open(\"data/labels_test_bw.pkl\", \"rb\"))\n",
    "\n",
    "# Shuffle train set\n",
    "data_train_bw, labels_train_bw = shuffle(data_train_bw, labels_train_bw, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dbe2c",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7660f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_std = scaler.fit_transform(data_train)\n",
    "X_test_std = scaler.transform(data_test)\n",
    "\n",
    "scaler_bw = StandardScaler()\n",
    "\n",
    "X_train_std_bw = scaler_bw.fit_transform(data_train_bw)\n",
    "X_test_std_bw = scaler_bw.transform(data_test_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a06114",
   "metadata": {},
   "source": [
    "## PCA\n",
    "We will use a 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a08ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features RGB: 3072\n",
      "Number of pricipal components RGB: 221\n",
      "Original number of features black and white: 1024\n",
      "Number of pricipal components black and white: 163\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of features RGB:\", X_train_std.shape[1])\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train_std)\n",
    "print(\"Number of pricipal components RGB:\", pca.n_components_)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(\"Original number of features black and white:\", X_train_std_bw.shape[1])\n",
    "pca_bw = PCA(0.95)\n",
    "pca_bw.fit(X_train_std_bw)\n",
    "print(\"Number of pricipal components black and white:\", pca_bw.n_components_)\n",
    "\n",
    "X_train_bw_pca = pca_bw.transform(X_train_std_bw)\n",
    "X_test_bw_pca = pca_bw.transform(X_test_std_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51688168",
   "metadata": {},
   "source": [
    "# Models\n",
    "We will use the hyperparameters obtained in the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6, weights=\"distance\", n_jobs=4).fit(X_train_std, labels_train)\n",
    "knn_bw = KNeighborsClassifier(n_neighbors=4, weights=\"distance\", n_jobs=4).fit(X_train_std_bw, labels_train)\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=6, weights=\"distance\", n_jobs=4).fit(X_train_pca, labels_train)\n",
    "knn_bw_pca = KNeighborsClassifier(n_neighbors=5, weights=\"distance\", n_jobs=4).fit(X_train_bw_pca, labels_train)\n",
    "print(\"KNN complete\")\n",
    "\n",
    "lr = LogisticRegression(penalty=\"l2\").fit(X_train_std, labels_train)\n",
    "lr_bw = LogisticRegression(penalty=\"l2\").fit(X_train_std_bw, labels_train)\n",
    "lr_pca = LogisticRegression(penalty=\"l2\").fit(X_train_pca, labels_train)\n",
    "lr_bw_pca = LogisticRegression(penalty=\"l2\").fit(X_train_bw_pca, labels_train)\n",
    "print(\"Logistic Regression complete\")\n",
    "\n",
    "rf = RandomForestClassifier(criterion=\"gini\", max_features=\"sqrt\", random_state=25, n_jobs=4).fit(X_train_std, labels_train)\n",
    "rf_bw = RandomForestClassifier(criterion=\"gini\", max_features=\"sqrt\", random_state=25, n_jobs=4).fit(X_train_std_bw, labels_train)\n",
    "rf_pca = RandomForestClassifier(criterion=\"gini\", max_features=\"sqrt\", random_state=25, n_jobs=4).fit(X_train_pca, labels_train)\n",
    "rf_bw_pca = RandomForestClassifier(criterion=\"gini\", max_features=\"sqrt\", random_state=25, n_jobs=4).fit(X_train_bw_pca, labels_train)\n",
    "print(\"Random Forest complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7b64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
